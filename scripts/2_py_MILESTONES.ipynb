{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_py_MILESTONES.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhVcWnJpXEYo",
        "colab_type": "text"
      },
      "source": [
        "# Python script for analyzing the EDH dataset\n",
        "*Created by: Vojtech Kase, Petra Hermankova*\n",
        "\n",
        "\n",
        "Requirements:\n",
        "*   Google Colab account \n",
        "*   Access to Sciencedata.dk or access alternatively to the dataset in JSON\n",
        "*   Basic knowledge of Python (how to run scripts in Python notebooks)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-R0Vdcrn1fq",
        "colab_type": "code",
        "outputId": "a5011e9f-b7a2-475b-f9fc-51e3489ea338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "### REQUIREMENTS - will install the libraries\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "### we do a lot of requests during the scrapping. Some of them with requests package, some of them with urllib\n",
        "import requests\n",
        "from urllib.request import urlopen \n",
        "from urllib.parse import quote  \n",
        "from bs4 import BeautifulSoup\n",
        "import xml.etree.cElementTree as ET\n",
        "\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# to avoid errors, we sometime use time.sleep(N) before retrying a request\n",
        "import time\n",
        "\n",
        "# the input data have typically a json structure\n",
        "import json\n",
        "import getpass\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "# for simple paralel computing:\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "!pip install --ignore-installed --index-url https://test.pypi.org/simple/ --no-deps sddk ### our own package under construction, always install to have up-to-date version\n",
        "import sddk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Collecting sddk\n",
            "  Using cached https://test-files.pythonhosted.org/packages/65/8b/d682c15a7335215ac119538ad8455b408cd7e8be4f6614678888dd2c88ed/sddk-0.0.7-py3-none-any.whl\n",
            "Installing collected packages: sddk\n",
            "Successfully installed sddk-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cK0r3WVvOH3",
        "colab_type": "text"
      },
      "source": [
        "## Establishing connection to the Sciencedata.dk: configure session and group URL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uTwTHVboJdw",
        "colab_type": "code",
        "outputId": "db28c9cb-86ec-4da1-e56a-64c69be1e284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "### configure session and groupurl\n",
        "### in the case of \"SDAM_root\", the group owner is Vojtech with username 648597@au.dk\n",
        "s, sddk_url = sddk.configure_session_and_url(\"SDAM_root\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sciencedata.dk username (format '123456@au.dk'): 648560@au.dk\n",
            "sciencedata.dk password: ··········\n",
            "endpoint for requests has been configured to: https://sciencedata.dk/files/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUU9syAHQEgs",
        "colab_type": "text"
      },
      "source": [
        "## Connecting to the preprocessed and enriched JSON file / dataframe from sciencedata.dk\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-hpGOCvBUM",
        "colab_type": "code",
        "outputId": "2021b8ca-fa85-4928-f306-f3b5a0b798fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "### Once the connection has been succesfuilly established, we can upload the data from sciencedata into Pandas dataframe\n",
        "### Look at Pandas documention to learn how to navigate Pandas dataframe with their endless functionality\n",
        "EDH_df = pd.DataFrame(s.get(sddk_url + \"SDAM_data/EDH/EDH_inscriptions_rich.json\").json())\n",
        "EDH_df.set_index(\"id\", inplace=True) ### perhaps the best index is the \"ID\"\n",
        "EDH_df.head(5) ### use \".head(5)\" to inspect first 5 rows of the dataframe"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-87d8d3cb055c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEDH_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msddk_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"SDAM_data/EDH/EDH_inscriptions_rich.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mEDH_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### perhaps the best index is the \"ID\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mEDH_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### use \".head(5)\" to inspect first 5 rows of the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkua1V-XW7Mh",
        "colab_type": "text"
      },
      "source": [
        "# Working offline (if the connection to Sciencedata.dk fails)\n",
        "You need to have an offline version of the enriched JSON file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IROR6Mh6G5Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for uploading offline files from the local computer (loading may take few minutes in case of large files)\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ6Jd-yCPILc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EDH_df = pd.read_json(\"EDH_inscriptions_rich.json\") # pandas load the json file and saves it as new object\n",
        "EDH_df.set_index(\"id\", inplace=True) ### indexing by ID\n",
        "EDH_df.head(5) ### use \".head(5)\" to inspect first 5 rows of the dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwPxDL6MRO6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect how many rows and columns we have\n",
        "EDH_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU_VoZxXa3Hv",
        "colab_type": "text"
      },
      "source": [
        "## Subsetting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AICYwYMRSsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect all unique values within \"type_of_inscription\"\n",
        "EDH_df[\"type_of_inscription\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdCSK6FuSATJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example how to subset the dataset, this time based on a specific string in the type of inscription\n",
        "EDH_miles = EDH_df[EDH_df[\"type_of_inscription\"].str.startswith(\"mile-/lea\", na=False)]\n",
        "len(EDH_miles) ### shows how many records in the dataset fulfils the condition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU0PH9TgSfVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EDH_miles.head(2) # shows the first (2) rows of the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69IYFnBNTqWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how to show only the dated ones\n",
        "EDH_miles_date = EDH_miles[EDH_miles[\"origdate_text\"].str.startswith(\"\", na=False)]\n",
        "len(EDH_miles_date) ### how long it is?\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi4UTq7mSSBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# selects only the milestones in the province Sardinia\n",
        "EDH_miles_sardinia = EDH_miles[EDH_miles[\"province_label\"].str.startswith(\"Sardinia\", na=False)]\n",
        "len(EDH_miles_sardinia)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFEVlXTEbATU",
        "colab_type": "text"
      },
      "source": [
        "### Saving the subset as CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s743pomQA0F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you need to save the subset into a CSV and save it into a local computer\n",
        "from google.colab import files\n",
        "EDH_miles.to_csv('EDH_milestones.csv') \n",
        "files.download('EDH_milestones.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHaarC5NUd5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prints as CSV into a local computer\n",
        "from google.colab import files\n",
        "EDH_miles_sardinia.to_csv('EDH_milestones_sardinia.csv') \n",
        "files.download('EDH_milestones_sardinia.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f6_SrIVQKB-",
        "colab_type": "text"
      },
      "source": [
        "## Inscriptions from one province (example of sardinia)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SrMnZtuQQhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EDH_df[\"province_label\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPhhnAYKZZO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subset based on the name of province \n",
        "EDH_sardinia = EDH_df[EDH_df[\"province_label\"].str.startswith(\"Sardinia\", na=False)]\n",
        "len(EDH_sardinia) ### how long it is?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXrHvh91Zlcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prints as CSV into a local computer\n",
        "from google.colab import files\n",
        "EDH_sardinia.to_csv('EDH_all_sardinia.csv') \n",
        "files.download('EDH_all_sardinia.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca1lP49obaVr",
        "colab_type": "text"
      },
      "source": [
        "### Example fo Thrace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYJrN1abwCDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### to get a smaller dataset \n",
        "EDH_thracia = EDH_df[EDH_df[\"province_label\"].str.startswith(\"Thracia\", na=False)]\n",
        "len(EDH_thracia) ### how long it is?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PAbSUiYv-4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prints as CSV into a local computer\n",
        "from google.colab import files\n",
        "EDH_thracia.to_csv('EDH_all_thracia.csv') \n",
        "files.download('EDH_all_thracia.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHRzpTnpbeta",
        "colab_type": "text"
      },
      "source": [
        "### Example of Meosia Inferior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ3wdc20xwXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### to get a smaller dataset \n",
        "EDH_moesia_inf = EDH_df[EDH_df[\"province_label\"].str.startswith(\"Moesia inf\", na=False)]\n",
        "len(EDH_moesia_inf) ### how long it is?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WFDyHnix4kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prints as CSV into a local computer\n",
        "from google.colab import files\n",
        "EDH_moesia_inf.to_csv('EDH_all_moesia_inf.csv') \n",
        "files.download('EDH_all_moesia_inf.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-JmhbJPmtgQ",
        "colab_type": "text"
      },
      "source": [
        "# Working with one CSV file\n",
        "\n",
        "If you prefer to work with one CSV file (containing a subset of all data), instead of the large JSON.\n",
        "\n",
        "The aim is to find all inscriptions containing mentions of a road, people using the road or any of the establishments and buildings associated with roads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG82y6olm4Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loads CSV and displays first three records to check\n",
        "Sardinia = pd.read_csv('EDH_all_sardinia.csv', sep=',')\n",
        "Sardinia.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tXNOB3rnpae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# searches through text for a specific term and outputs only those inscriptions containing the full term\n",
        "language = ['Latin', 'Greek']\n",
        "sardinia_lang = Sardinia.loc[Sardinia['language'].isin(language)]\n",
        "sardinia_lang.head(2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB8w08E0qh9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using partial strings to find specific inscriptions, https://stackoverflow.com/questions/11350770/select-by-partial-string-from-a-pandas-dataframe\n",
        "# example of one term search, using regexes\n",
        "Sardinia[Sardinia['transcription'].str.contains(r'viat')]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtQyJbostSu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list based search, searches for all the occurences of the terms in the list roads_vocab\n",
        "roads_vocab = ['\\bvia\\b', '\\bviat', '\\bmansio', '\\bmutatio','\\bmilia', 'millia', '\\bpassuum', '\\bcaput', '\\bpons', '\\bpont']\n",
        "Sardinia[Sardinia['transcription'].str.contains('|'.join(roads_vocab))]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0ROjTqC5ik6",
        "colab_type": "text"
      },
      "source": [
        "### List based search for an entire JSON dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMySxI7Y5wIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for uploading offline files from the local computer (loading will take few minutes in case of large files)\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7TnvqX2-aH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EDH_df = pd.read_json(\"EDH_inscriptions_rich.json\") # pandas load the json file and saves it as new object\n",
        "EDH_df.set_index(\"id\", inplace=True) ### index is the \"ID\"\n",
        "EDH_df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJKfV3E-hjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list based serach, searches for all terms in the list\n",
        "roads_vocab = ['\\bvia\\b', '\\bviat', '\\bmansio', '\\bmutatio','\\bmilia', 'millia', '\\bpassuum', '\\bcaput', '\\bpons', '\\bpont']\n",
        "EDH_roads_vocab = EDH_df[EDH_df['transcription'].str.contains('|'.join(roads_vocab), na=False)]\n",
        "len(EDH_roads_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4zG3yyP_iwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prints as CSV into a local computer\n",
        "from google.colab import files\n",
        "EDH_roads_vocab.to_csv('EDH_roads_vocab.csv') \n",
        "files.download('EDH_roads_vocab.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}